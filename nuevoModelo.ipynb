{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import gc\n",
    "from tqdm import tqdm\n",
    "from sklearn.impute import SimpleImputer\n",
    "import lightgbm as lgb\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Armado de features**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "objective = 0\n",
    "windows = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_time = 24*3600*3\n",
    "\n",
    "time_windows = [('2019-04-18 00:00:00.000000', '2019-04-21 00:00:00.000000'), ('2019-04-19 00:00:00.000000', '2019-04-22 00:00:00.000000'), \n",
    "                ('2019-04-20 00:00:00.000000', '2019-04-23 00:00:00.000000'), ('2019-04-21 00:00:00.000000', '2019-04-24 00:00:00.000000'), \n",
    "                ('2019-04-24 00:00:00.000000', '2019-04-27 00:00:00.000000')]\n",
    "time_labels = [('2019-04-21 00:00:00.000000', '2019-04-24 00:00:00.000000'), ('2019-04-22 00:00:00.000000', '2019-04-25 00:00:00.000000'), \n",
    "               ('2019-04-23 00:00:00.000000', '2019-04-26 00:00:00.000000'), ('2019-04-24 00:00:00.000000', '2019-04-27 00:00:00.000000')]\n",
    "days = [18, 19, 20, 21, 24]\n",
    "\n",
    "model = pd.DataFrame()\n",
    "targets = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 4/4 [13:49<00:00, 206.63s/it]\n"
     ]
    }
   ],
   "source": [
    "for i in tqdm(range(4)):\n",
    "    window = i+1\n",
    "    if window <= 4:\n",
    "        auctions_label = pd.read_pickle('data/auctions_w'+str(window)+'_label.pkl')\n",
    "        installs_label = pd.read_pickle('data/installs_w'+str(window)+'_label.pkl')\n",
    "\n",
    "    auctions = pd.read_pickle('data/auctions_w'+str(window)+'.pkl')\n",
    "    gb = auctions.groupby('ref_hash')\n",
    "    auctions['n_auctions'] = gb['date'].transform('count')\n",
    "    auctions['last_auction'] = gb['date'].transform('max')\n",
    "    auctions['first_auction'] = gb['date'].transform('min')\n",
    "    auctions['diff_auctions'] = (auctions['last_auction'] - auctions['first_auction']).dt.total_seconds()\n",
    "    auctions['mean_time_auction'] = 0\n",
    "    auctions.loc[auctions['n_auctions'] > 1, 'mean_time_auction'] = ((auctions['last_auction'] - auctions['first_auction'])/ \\\n",
    "                                     (auctions['n_auctions'] -1)).dt.total_seconds()\n",
    "    auctions['first_auction_sec'] = (auctions['first_auction'] - pd.Timestamp(time_windows[window-1][0])).dt.total_seconds()\n",
    "    auctions['last_auction_sec'] = (auctions['last_auction'] - pd.Timestamp(time_windows[window-1][0])).dt.total_seconds()\n",
    "    auctions['last_auction_sec_to_end'] = (pd.Timestamp(time_windows[window-1][1]) - auctions['last_auction']).dt.total_seconds()\n",
    "    auctions['ref_type_id_1'] = auctions['ref_type_id'].apply(lambda x: 1 if x==1 else 0)\n",
    "    auctions['ref_type_id_7'] = auctions['ref_type_id'].apply(lambda x: 1 if x==7 else 0)\n",
    "    auctions['day'] = (auctions['date'].dt.day) - days[window-1]\n",
    "    gb = auctions.groupby('ref_hash')\n",
    "    auctions = auctions.join(gb['source_id'].value_counts().unstack().add_prefix('source_'), on='ref_hash')\n",
    "    auctions = pd.get_dummies(auctions, columns=['day'])\n",
    "    gb = auctions.groupby('ref_hash')\n",
    "    auctions['day_0'] = gb['day_0'].transform('sum')\n",
    "    auctions['day_1'] = gb['day_1'].transform('sum')\n",
    "    auctions['day_2'] = gb['day_2'].transform('sum')\n",
    "\n",
    "    auctions.drop_duplicates(subset='ref_hash', inplace=True)\n",
    "    auctions.drop(columns=['date', 'ref_type_id', 'last_auction', 'first_auction', 'source_id'], inplace=True)\n",
    "    auctions = auctions.fillna(0)\n",
    "\n",
    "    clicks = pd.read_pickle('data/clicks_w'+str(window)+'.pkl')\n",
    "    clicks.drop(columns=['action_id', 'agent_device'])\n",
    "    gb = clicks.groupby('ref_hash')\n",
    "    clicks['n_clicks'] = gb['created'].transform('count')\n",
    "    clicks['last_click'] = gb['created'].transform('max')\n",
    "    clicks['first_click'] = gb['created'].transform('min')\n",
    "    clicks['diff_clicks'] = (clicks['last_click'] - clicks['first_click']).dt.total_seconds()\n",
    "    clicks['mean_time_click'] = 0\n",
    "    clicks.loc[clicks['n_clicks'] > 1, 'mean_time_click'] = ((clicks['last_click'] - clicks['first_click'])/ \\\n",
    "                                     (clicks['n_clicks'] -1)).dt.total_seconds()\n",
    "    clicks['first_click_sec'] = (clicks['first_click'] - pd.Timestamp(time_windows[window-1][0])).dt.total_seconds()\n",
    "    clicks['last_click_sec'] = (clicks['last_click'] - pd.Timestamp(time_windows[window-1][0])).dt.total_seconds()\n",
    "    clicks['wifi_connection'] = clicks['wifi_connection'].map({True: 1, False: 0})\n",
    "    clicks['timeToClick_mean'] = clicks.groupby('ref_hash')['timeToClick'].transform('mean')\n",
    "    clicks.loc[clicks.touchX == 'Infinity', 'touchX'] = 1\n",
    "    clicks.loc[clicks.touchY == 'Infinity', 'touchY'] = 10\n",
    "    clicks[\"touchX\"] = pd.to_numeric(clicks[\"touchX\"])\n",
    "    clicks[\"touchY\"] = pd.to_numeric(clicks[\"touchY\"])\n",
    "    clicks['touch_bottom'] = clicks['touchY'].apply(lambda x: 1 if x<=1 else 0)\n",
    "    clicks['touch_bottom2'] = clicks['touchY'].apply(lambda x: 1 if x>1 and x<=2 else 0)\n",
    "    top_10_carrier_id = clicks['carrier_id'].value_counts().head(10)\n",
    "    clicks.loc[(~clicks['carrier_id'].isin(top_10_carrier_id.index))&(clicks['carrier_id'].notnull()), 'carrier_id'] = 'Other'\n",
    "    gb = clicks.groupby('ref_hash')\n",
    "    clicks = clicks.join(gb['advertiser_id'].value_counts().unstack().add_prefix('advertiser_id_'), on='ref_hash')\n",
    "    clicks = clicks.join(gb['source_id'].value_counts().unstack().add_prefix('source_id_'), on='ref_hash')\n",
    "    clicks['touchX_mean'] = gb['touchX'].transform('mean')\n",
    "    clicks['touchY_mean'] = gb['touchY'].transform('mean')\n",
    "    clicks['touchs_in_bottom'] = gb['touch_bottom'].transform('sum')\n",
    "    clicks['touchs_in_bottom2'] = gb['touch_bottom2'].transform('sum')\n",
    "    clicks['latitude_mean'] = gb['latitude'].transform('mean')\n",
    "    clicks['longitude_mean'] = gb['longitude'].transform('mean')\n",
    "    clicks['timeToClick_mean'] = clicks['timeToClick_mean'].fillna(clicks['timeToClick_mean'].mean())\n",
    "    clicks['touchX_mean'] = clicks['touchX_mean'].fillna(clicks['touchX_mean'].mean())\n",
    "    clicks['touchY_mean'] = clicks['touchY_mean'].fillna(clicks['touchY_mean'].mean())\n",
    "\n",
    "    clicks.drop_duplicates(subset='ref_hash', inplace=True)\n",
    "    clicks = clicks.drop(columns=['advertiser_id', 'source_id', 'created', 'country_code', 'latitude', 'longitude', 'wifi_connection', 'carrier_id', 'trans_id', 'agent_device',\n",
    "       'os_minor', 'os_major', 'specs_brand', 'brand', 'timeToClick', 'touchX', 'touchY', 'ref_type', 'last_click', 'first_click', 'touch_bottom', 'touch_bottom2', 'action_id'])\n",
    "\n",
    "    modelo = pd.merge(auctions, clicks, on='ref_hash', how='outer')\n",
    "    auctions = 0\n",
    "    clicks = 0\n",
    "    gc.collect()\n",
    "    \n",
    "    installs = pd.read_pickle('data/installs_w'+str(window)+'.pkl')\n",
    "    installs = installs.drop(columns=['device_countrycode', 'ip_address', 'event_uuid', 'click_hash', 'device_brand', 'device_model'])\n",
    "    #installs = installs.drop(columns=['device_language', 'device_countrycode', 'ip_address', 'event_uuid', 'device_brand', 'device_model', 'click_hash', 'session_user_agent'])\n",
    "    installs.loc[installs['kind'] == 'OPEN', 'kind'] = 'Open'\n",
    "    installs.loc[installs['kind'] == 'app open', 'kind'] = 'app_open'\n",
    "    installs.loc[installs['kind'] == 'af app open', 'kind'] = 'af_app_opened'\n",
    "    installs.loc[installs['kind'] == 'af_app_opend', 'kind'] = 'af_app_opened'\n",
    "    installs.loc[installs['kind'] == 'Session Begin', 'kind'] = 'sessionbegin'\n",
    "    installs.loc[installs['kind'] == 'signed in', 'kind'] = 'Sign In'\n",
    "    top_20_installs_kind = installs['kind'].value_counts().head(20)\n",
    "    installs.loc[(~installs['kind'].isin(top_20_installs_kind.index))&(installs['kind'].notnull()), 'kind'] = 'Other'\n",
    "    top_15_installs_app = installs['application_id'].value_counts().head(15)\n",
    "    installs.loc[(~installs['application_id'].isin(top_15_installs_app.index))&(installs['application_id'].notnull()), 'application_id'] = 'Other'\n",
    "    installs['created'] = pd.to_datetime(installs['created'], format='%Y-%m-%d %H:%M:%S')\n",
    "    installs['wifi_installs'] = installs['wifi'].map({True: 1, False: 0})\n",
    "    installs['attributed'] = installs['attributed'].map({True: 1, False: 0})\n",
    "    installs['implicit'] = installs['implicit'].map({True: 1, False: 0})\n",
    "    gb = installs.groupby('ref_hash')\n",
    "    installs = installs.join(gb['kind'].value_counts().unstack().add_prefix('kind_'), on='ref_hash')\n",
    "    installs = installs.join(gb['application_id'].value_counts().unstack().add_prefix('application_id_'), on='ref_hash')\n",
    "    installs['wifi_installs_mean'] = gb['wifi_installs'].transform('mean')\n",
    "    installs['attributed_installs_mean'] = gb['attributed'].transform('mean')\n",
    "    installs['n_installs'] = gb['created'].transform('count')\n",
    "    installs['last_install'] = gb['created'].transform('max')\n",
    "    installs['first_install'] = gb['created'].transform('min')\n",
    "    installs['diff_installs'] = (installs['last_install'] - installs['first_install']).dt.total_seconds()\n",
    "    installs['mean_time_install'] = 0\n",
    "    installs.loc[installs['n_installs'] > 1, 'mean_time_install'] = ((installs['last_install'] - installs['first_install'])/ \\\n",
    "                                     (installs['n_installs'] -1)).dt.total_seconds()\n",
    "    installs['first_install_sec'] = (installs['first_install'] - pd.Timestamp(time_windows[window-1][0])).dt.total_seconds()\n",
    "    installs['last_install_sec'] = (installs['last_install'] - pd.Timestamp(time_windows[window-1][0])).dt.total_seconds()\n",
    "    \n",
    "    installs.drop_duplicates(subset='ref_hash', inplace=True)\n",
    "    installs.drop(columns=['created', 'application_id', 'ref_type', 'attributed',\n",
    "       'implicit', 'user_agent', 'kind', 'wifi', 'trans_id', 'device_language',\n",
    "       'wifi_installs', 'last_install', 'first_install', 'session_user_agent'], inplace=True)\n",
    "\n",
    "    modelo = pd.merge(modelo, installs, on='ref_hash', how='outer')\n",
    "    \n",
    "    installs = 0\n",
    "    gc.collect()\n",
    "    \n",
    "    events = pd.read_pickle('data/events_w'+str(window)+'.pkl')\n",
    "    events.drop(columns=['event_uuid', 'ip_address', 'index', 'device_countrycode', 'trans_id'], inplace=True)\n",
    "\n",
    "    events['attributed'] = events['attributed'].map({True: 1, False: 0})\n",
    "    events['wifi'] = events['wifi'].map({True: 1, False: 0})\n",
    "    top_15_events_id = events['event_id'].value_counts().head(15)\n",
    "    events.loc[(~events['event_id'].isin(top_15_events_id.index))&(events['event_id'].notnull()), 'event_id'] = 'Other'\n",
    "    top_20_application_id = events['application_id'].value_counts().head(20)\n",
    "    events.loc[(~events['application_id'].isin(top_20_application_id.index))&(events['application_id'].notnull()), 'application_id'] = 'Other'\n",
    "    #top_15_device_os_version = events['device_os_version'].value_counts().head(15)\n",
    "    #events.loc[(~events['device_os_version'].isin(top_15_device_os_version.index))&(events['device_os_version'].notnull()), 'device_os_version'] = 'Other'\n",
    "    #top_15_device_brand = events['device_brand'].value_counts().head(15)\n",
    "    #events.loc[(~events['device_brand'].isin(top_15_device_brand.index))&(events['device_brand'].notnull()), 'device_brand'] = 'Other'\n",
    "    #top_15_device_model = events['device_model'].value_counts().head(15)\n",
    "    #events.loc[(~events['device_model'].isin(top_15_device_model.index))&(events['device_model'].notnull()), 'device_model'] = 'Other'\n",
    "    top_10_session_user_agent = events['session_user_agent'].value_counts().head(10)\n",
    "    events.loc[(~events['session_user_agent'].isin(top_10_session_user_agent.index))&(events['session_user_agent'].notnull()), 'session_user_agent'] = 'Other'\n",
    "    #top_10_carrier = events['carrier'].value_counts().head(10)\n",
    "    #events.loc[(~events['carrier'].isin(top_10_carrier.index))&(events['carrier'].notnull()), 'carrier'] = 'Other'\n",
    "    top_15_kind = events['kind'].value_counts().head(15)\n",
    "    events.loc[(~events['kind'].isin(top_15_kind.index))&(events['kind'].notnull()), 'kind'] = 'Other'\n",
    "    #top_15_device_language = events['device_language'].value_counts().head(15)\n",
    "    #events.loc[(~events['device_language'].isin(top_15_device_language.index))&(events['device_language'].notnull()), 'device_language'] = 'Other'\n",
    "\n",
    "    gb = events.groupby('ref_hash')\n",
    "    events = events.join(gb['event_id'].value_counts().unstack().add_prefix('event_id_'), on='ref_hash')\n",
    "    events = events.join(gb['application_id'].value_counts().unstack().add_prefix('application_id_'), on='ref_hash')\n",
    "    #events = events.join(gb['device_os_version'].value_counts().unstack().add_prefix('device_os_version_'), on='ref_hash')\n",
    "    #events = events.join(gb['device_brand'].value_counts().unstack().add_prefix('device_brand_'), on='ref_hash')\n",
    "    #events = events.join(gb['device_model'].value_counts().unstack().add_prefix('device_model_'), on='ref_hash')\n",
    "    #events = events.join(gb['carrier'].value_counts().unstack().add_prefix('carrier_'), on='ref_hash')\n",
    "    events = events.join(gb['session_user_agent'].value_counts().unstack().add_prefix('session_user_agent_'), on='ref_hash')\n",
    "    events = events.join(gb['kind'].value_counts().unstack().add_prefix('kind_'), on='ref_hash')\n",
    "    #events = events.join(gb['device_language'].value_counts().unstack().add_prefix('device_language_'), on='ref_hash')\n",
    "\n",
    "    events['n_events'] = gb['date'].transform('count')\n",
    "    events['attributed_events_mean'] = gb['attributed'].transform('mean')\n",
    "    events['wifi_events_mean'] = gb['wifi'].transform('mean')\n",
    "    events['first_event'] = gb['date'].transform('min')\n",
    "    events['last_event'] = gb['date'].transform('max')\n",
    "    events['diff_events'] = (events['last_event'] - events['first_event']).dt.total_seconds()\n",
    "    events['mean_time_events'] = 0\n",
    "    events.loc[events['n_events'] > 1, 'mean_time_events'] = ((events['last_event'] - events['first_event'])/ \\\n",
    "                                     (events['n_events'] -1)).dt.total_seconds()\n",
    "    events['first_event_sec'] = (events['first_event'] - pd.Timestamp(time_windows[window-1][0])).dt.total_seconds()\n",
    "    events['last_event_sec'] = (events['last_event'] - pd.Timestamp(time_windows[window-1][0])).dt.total_seconds()\n",
    "    \n",
    "    events.drop_duplicates(subset='ref_hash', inplace=True)\n",
    "    events = events.drop(columns=['date', 'event_id', 'ref_type', 'application_id', 'attributed', 'device_os_version', 'device_brand', 'device_model', \n",
    "       'device_city', 'session_user_agent', 'user_agent', 'carrier', 'kind', 'device_os', 'wifi', 'connection_type', 'device_language', 'first_event', 'last_event'])\n",
    "    \n",
    "    modelo = pd.merge(modelo, events, on='ref_hash', how='outer')\n",
    "    \n",
    "    events = 0\n",
    "    gc.collect()\n",
    "\n",
    "    if window <= 4:\n",
    "        modelo = pd.merge(modelo, auctions_label, on='ref_hash', how='outer')\n",
    "        modelo = pd.merge(modelo, installs_label, on='ref_hash', how='outer')\n",
    "        modelo['time_appearence'] = modelo['time_appearence'].fillna(max_time)\n",
    "        modelo['time_appearence_install'] = modelo['time_appearence_install'].fillna(max_time)\n",
    "\n",
    "    model = pd.concat([model, modelo], sort=False)\n",
    "\n",
    "    modelo = 0\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Imputacion valores\n",
    "model['last_auction_sec_to_end'].fillna(24*3600*3, inplace=True)\n",
    "\n",
    "features = ['diff_auctions', 'mean_time_auction', 'diff_clicks',\n",
    "            'mean_time_click', 'timeToClick_mean', 'touchX_mean', \n",
    "            'touchY_mean', 'latitude_mean', 'longitude_mean',\n",
    "            'wifi_installs_mean', 'attributed_installs_mean', 'diff_installs',\n",
    "            'mean_time_install', 'time_appearence', 'time_appearence_install', \n",
    "            'attributed_events_mean', 'wifi_events_mean', 'diff_events',\n",
    "            'mean_time_events']\n",
    "\n",
    "for feature in features:\n",
    "    if feature not in model:\n",
    "        continue\n",
    "    else:\n",
    "        model[feature] = model[feature].fillna(model[feature].mean())\n",
    "\n",
    "for feature in model.columns:\n",
    "    model[feature].fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_features = ['time_appearence', 'time_appearence_install']\n",
    "train, test = train_test_split(model.drop(columns=['ref_hash']), test_size=0.2)\n",
    "\n",
    "train_Y = train[target_features[objective]]\n",
    "train_X = train.drop(columns=target_features)\n",
    "test_Y = test[target_features[objective]]\n",
    "test_X = test.drop(columns=target_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgb_model = lgb.LGBMModel(boosting_type=\"gbdt\", num_leaves=100, max_depth=None, learning_rate=0.05, n_estimators=500, \n",
    "                      max_bin=300, subsample_for_bin=50000, objective='regression', min_split_gain=0, min_child_weight=5, \n",
    "                      min_child_samples=10, subsample=1, subsample_freq=1, colsample_bytree=1, reg_alpha=0, reg_lambda=0, \n",
    "                      seed=0, silent=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'LGBMModel' object has no attribute 'save_model'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-25-ca1210396ffd>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mlgb_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'nuevos_modelos/lightgbm1'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m: 'LGBMModel' object has no attribute 'save_model'"
     ]
    }
   ],
   "source": [
    "lgb_model.save_model('nuevos_modelos/lightgbm1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgb_model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LGBMModel(boosting_type='gbdt', class_weight=None, colsample_bytree=1,\n",
       "     importance_type='split', learning_rate=0.05, max_bin=300,\n",
       "     max_depth=None, min_child_samples=10, min_child_weight=5,\n",
       "     min_split_gain=0, n_estimators=500, n_jobs=-1, num_leaves=100,\n",
       "     objective='regression', random_state=None, reg_alpha=0, reg_lambda=0,\n",
       "     seed=0, silent=True, subsample=1, subsample_for_bin=50000,\n",
       "     subsample_freq=1)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lgb_model.fit(train_X, train_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-24-1d58e1f90163>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0merror_train\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmean_squared_error\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlgb_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_X\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_Y\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0merror_train\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Martin\\Anaconda3\\lib\\site-packages\\lightgbm\\sklearn.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, X, raw_score, num_iteration, pred_leaf, pred_contrib, **kwargs)\u001b[0m\n\u001b[0;32m    562\u001b[0m                              % (self._n_features, n_features))\n\u001b[0;32m    563\u001b[0m         return self.booster_.predict(X, raw_score=raw_score, num_iteration=num_iteration,\n\u001b[1;32m--> 564\u001b[1;33m                                      pred_leaf=pred_leaf, pred_contrib=pred_contrib, **kwargs)\n\u001b[0m\u001b[0;32m    565\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    566\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Martin\\Anaconda3\\lib\\site-packages\\lightgbm\\basic.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, data, num_iteration, raw_score, pred_leaf, pred_contrib, data_has_header, is_reshape, pred_parameter, **kwargs)\u001b[0m\n\u001b[0;32m   2146\u001b[0m         return predictor.predict(data, num_iteration,\n\u001b[0;32m   2147\u001b[0m                                  \u001b[0mraw_score\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpred_leaf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpred_contrib\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2148\u001b[1;33m                                  data_has_header, is_reshape)\n\u001b[0m\u001b[0;32m   2149\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2150\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mrefit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdecay_rate\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.9\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Martin\\Anaconda3\\lib\\site-packages\\lightgbm\\basic.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, data, num_iteration, raw_score, pred_leaf, pred_contrib, data_has_header, is_reshape)\u001b[0m\n\u001b[0;32m    410\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mDataset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    411\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Cannot use Dataset instance for prediction, please use raw data instead\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 412\u001b[1;33m         \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_data_from_pandas\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpandas_categorical\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    413\u001b[0m         \u001b[0mpredict_type\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mC_API_PREDICT_NORMAL\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    414\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mraw_score\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Martin\\Anaconda3\\lib\\site-packages\\lightgbm\\basic.py\u001b[0m in \u001b[0;36m_data_from_pandas\u001b[1;34m(data, feature_name, categorical_feature, pandas_categorical)\u001b[0m\n\u001b[0;32m    247\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Input data must be 2 dimensional and non empty.'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    248\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mfeature_name\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'auto'\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfeature_name\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 249\u001b[1;33m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrename\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    250\u001b[0m         \u001b[0mcat_cols\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mselect_dtypes\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minclude\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'category'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    251\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mpandas_categorical\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# train dataset\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Martin\\Anaconda3\\lib\\site-packages\\pandas\\util\\_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    195\u001b[0m         \u001b[1;33m@\u001b[0m\u001b[0mwraps\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    196\u001b[0m         \u001b[1;32mdef\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 197\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    198\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    199\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mPY2\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Martin\\Anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36mrename\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   4023\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'axis'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4024\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'mapper'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 4025\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrename\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   4026\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4027\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mSubstitution\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0m_shared_doc_kwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Martin\\Anaconda3\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36mrename\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1089\u001b[0m                 \u001b[0mlevel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maxes\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_level_number\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlevel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1090\u001b[0m             result._data = result._data.rename_axis(f, axis=baxis, copy=copy,\n\u001b[1;32m-> 1091\u001b[1;33m                                                     level=level)\n\u001b[0m\u001b[0;32m   1092\u001b[0m             \u001b[0mresult\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_clear_item_cache\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1093\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Martin\\Anaconda3\\lib\\site-packages\\pandas\\core\\internals\\managers.py\u001b[0m in \u001b[0;36mrename_axis\u001b[1;34m(self, mapper, axis, copy, level)\u001b[0m\n\u001b[0;32m    168\u001b[0m         \u001b[0mlevel\u001b[0m \u001b[1;33m:\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdefault\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    169\u001b[0m         \"\"\"\n\u001b[1;32m--> 170\u001b[1;33m         \u001b[0mobj\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdeep\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    171\u001b[0m         \u001b[0mobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_axis\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_transform_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maxes\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmapper\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    172\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Martin\\Anaconda3\\lib\\site-packages\\pandas\\core\\internals\\managers.py\u001b[0m in \u001b[0;36mcopy\u001b[1;34m(self, deep)\u001b[0m\n\u001b[0;32m    732\u001b[0m             \u001b[0mnew_axes\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maxes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    733\u001b[0m         return self.apply('copy', axes=new_axes, deep=deep,\n\u001b[1;32m--> 734\u001b[1;33m                           do_integrity_check=False)\n\u001b[0m\u001b[0;32m    735\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    736\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mas_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtranspose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mitems\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Martin\\Anaconda3\\lib\\site-packages\\pandas\\core\\internals\\managers.py\u001b[0m in \u001b[0;36mapply\u001b[1;34m(self, f, axes, filter, do_integrity_check, consolidate, **kwargs)\u001b[0m\n\u001b[0;32m    393\u001b[0m                                             copy=align_copy)\n\u001b[0;32m    394\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 395\u001b[1;33m             \u001b[0mapplied\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mb\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    396\u001b[0m             \u001b[0mresult_blocks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_extend_blocks\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mapplied\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult_blocks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    397\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Martin\\Anaconda3\\lib\\site-packages\\pandas\\core\\internals\\blocks.py\u001b[0m in \u001b[0;36mcopy\u001b[1;34m(self, deep)\u001b[0m\n\u001b[0;32m    751\u001b[0m         \u001b[0mvalues\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    752\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mdeep\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 753\u001b[1;33m             \u001b[0mvalues\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvalues\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    754\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmake_block_same_class\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    755\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mMemoryError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "error_train = np.sqrt(mean_squared_error(lgb_model.predict(train_X), train_Y))\n",
    "error_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "96232.23782588485"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "error_test = np.sqrt(mean_squared_error(lgb_model.predict(test_X), test_Y))\n",
    "error_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('logs/models.txt', mode='a') as log:\n",
    "    log.write('LGBM; {}; {}; {}; {}; {} \\n'.format(target_features[objective], lgb_model.get_params(), list(model.columns), error_train, error_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "if window <= 4:\n",
    "    auctions_label = pd.read_pickle('data/auctions_w'+str(window)+'_label.pkl')\n",
    "    installs_label = pd.read_pickle('data/installs_w'+str(window)+'_label.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_windows = [('2019-04-18 00:00:00.000000', '2019-04-21 00:00:00.000000'), ('2019-04-19 00:00:00.000000', '2019-04-22 00:00:00.000000'), \n",
    "                ('2019-04-20 00:00:00.000000', '2019-04-23 00:00:00.000000'), ('2019-04-21 00:00:00.000000', '2019-04-24 00:00:00.000000'), \n",
    "                ('2019-04-24 00:00:00.000000', '2019-04-27 00:00:00.000000')]\n",
    "time_labels = [('2019-04-21 00:00:00.000000', '2019-04-24 00:00:00.000000'), ('2019-04-22 00:00:00.000000', '2019-04-25 00:00:00.000000'), \n",
    "               ('2019-04-23 00:00:00.000000', '2019-04-26 00:00:00.000000'), ('2019-04-24 00:00:00.000000', '2019-04-27 00:00:00.000000')]\n",
    "days = [18, 19, 20, 21, 24]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "auctions.drop_duplicates(subset='ref_hash', inplace=True)\n",
    "auctions.drop(columns=['date', 'ref_type_id', 'last_auction', 'first_auction', 'source_id'], inplace=True)\n",
    "auctions = auctions.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "clicks = pd.read_pickle('data/clicks_w'+str(window)+'.pkl')\n",
    "clicks.drop(columns=['action_id', 'agent_device'])\n",
    "gb = clicks.groupby('ref_hash')\n",
    "clicks['n_clicks'] = gb['created'].transform('count')\n",
    "clicks['last_click'] = gb['created'].transform('max')\n",
    "clicks['first_click'] = gb['created'].transform('min')\n",
    "clicks['diff_clicks'] = (clicks['last_click'] - clicks['first_click']).dt.total_seconds()\n",
    "clicks['mean_time_click'] = 0\n",
    "clicks.loc[clicks['n_clicks'] > 1, 'mean_time_click'] = ((clicks['last_click'] - clicks['first_click'])/ \\\n",
    "                                 (clicks['n_clicks'] -1)).dt.total_seconds()\n",
    "clicks['first_click_sec'] = (clicks['first_click'] - pd.Timestamp(time_windows[window-1][0])).dt.total_seconds()\n",
    "clicks['last_click_sec'] = (clicks['last_click'] - pd.Timestamp(time_windows[window-1][0])).dt.total_seconds()\n",
    "clicks['wifi_connection'] = clicks['wifi_connection'].map({True: 1, False: 0})\n",
    "clicks['timeToClick_mean'] = clicks.groupby('ref_hash')['timeToClick'].transform('mean')\n",
    "clicks.loc[clicks.touchX == 'Infinity', 'touchX'] = 1\n",
    "clicks.loc[clicks.touchY == 'Infinity', 'touchY'] = 10\n",
    "clicks[\"touchX\"] = pd.to_numeric(clicks[\"touchX\"])\n",
    "clicks[\"touchY\"] = pd.to_numeric(clicks[\"touchY\"])\n",
    "clicks['touch_bottom'] = clicks['touchY'].apply(lambda x: 1 if x<=1 else 0)\n",
    "clicks['touch_bottom2'] = clicks['touchY'].apply(lambda x: 1 if x>1 and x<=2 else 0)\n",
    "\n",
    "top_10_carrier_id = clicks['carrier_id'].value_counts().head(10)\n",
    "clicks.loc[(~clicks['carrier_id'].isin(top_10_carrier_id.index))&(clicks['carrier_id'].notnull()), 'carrier_id'] = 'Other'\n",
    "\n",
    "gb = clicks.groupby('ref_hash')\n",
    "clicks = clicks.join(gb['advertiser_id'].value_counts().unstack().add_prefix('advertiser_id_'), on='ref_hash')\n",
    "clicks = clicks.join(gb['source_id'].value_counts().unstack().add_prefix('source_id_'), on='ref_hash')\n",
    "clicks['touchX_mean'] = gb['touchX'].transform('mean')\n",
    "clicks['touchY_mean'] = gb['touchY'].transform('mean')\n",
    "clicks['touchs_in_bottom'] = gb['touch_bottom'].transform('sum')\n",
    "clicks['touchs_in_bottom2'] = gb['touch_bottom2'].transform('sum')\n",
    "clicks['latitude_mean'] = gb['latitude'].transform('mean')\n",
    "clicks['longitude_mean'] = gb['longitude'].transform('mean')\n",
    "clicks['timeToClick_mean'] = clicks['timeToClick_mean'].fillna(clicks['timeToClick_mean'].mean())\n",
    "clicks['touchX_mean'] = clicks['touchX_mean'].fillna(clicks['touchX_mean'].mean())\n",
    "clicks['touchY_mean'] = clicks['touchY_mean'].fillna(clicks['touchY_mean'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "clicks.drop_duplicates(subset='ref_hash', inplace=True)\n",
    "clicks = clicks.drop(columns=['advertiser_id', 'source_id', 'created', 'country_code', 'latitude', 'longitude', 'wifi_connection', 'carrier_id', 'trans_id', 'agent_device',\n",
    "       'os_minor', 'os_major', 'specs_brand', 'brand', 'timeToClick', 'touchX', 'touchY', 'ref_type', 'last_click', 'first_click', 'touch_bottom', 'touch_bottom2', 'action_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "events = pd.read_pickle('data/events_w'+str(window)+'.pkl')\n",
    "events.drop(columns=['event_uuid', 'ip_address', 'index', 'device_countrycode', 'trans_id'], inplace=True)\n",
    "\n",
    "events['attributed'] = events['attributed'].map({True: 1, False: 0})\n",
    "events['wifi'] = events['wifi'].map({True: 1, False: 0})\n",
    "top_15_events_id = events['event_id'].value_counts().head(15)\n",
    "events.loc[(~events['event_id'].isin(top_15_events_id.index))&(events['event_id'].notnull()), 'event_id'] = 'Other'\n",
    "top_20_application_id = events['application_id'].value_counts().head(20)\n",
    "events.loc[(~events['application_id'].isin(top_20_application_id.index))&(events['application_id'].notnull()), 'application_id'] = 'Other'\n",
    "#top_15_device_os_version = events['device_os_version'].value_counts().head(15)\n",
    "#events.loc[(~events['device_os_version'].isin(top_15_device_os_version.index))&(events['device_os_version'].notnull()), 'device_os_version'] = 'Other'\n",
    "#top_15_device_brand = events['device_brand'].value_counts().head(15)\n",
    "#events.loc[(~events['device_brand'].isin(top_15_device_brand.index))&(events['device_brand'].notnull()), 'device_brand'] = 'Other'\n",
    "#top_15_device_model = events['device_model'].value_counts().head(15)\n",
    "#events.loc[(~events['device_model'].isin(top_15_device_model.index))&(events['device_model'].notnull()), 'device_model'] = 'Other'\n",
    "top_10_session_user_agent = events['session_user_agent'].value_counts().head(10)\n",
    "events.loc[(~events['session_user_agent'].isin(top_10_session_user_agent.index))&(events['session_user_agent'].notnull()), 'session_user_agent'] = 'Other'\n",
    "#top_10_carrier = events['carrier'].value_counts().head(10)\n",
    "#events.loc[(~events['carrier'].isin(top_10_carrier.index))&(events['carrier'].notnull()), 'carrier'] = 'Other'\n",
    "top_15_kind = events['kind'].value_counts().head(15)\n",
    "events.loc[(~events['kind'].isin(top_15_kind.index))&(events['kind'].notnull()), 'kind'] = 'Other'\n",
    "#top_15_device_language = events['device_language'].value_counts().head(15)\n",
    "#events.loc[(~events['device_language'].isin(top_15_device_language.index))&(events['device_language'].notnull()), 'device_language'] = 'Other'\n",
    "\n",
    "gb = events.groupby('ref_hash')\n",
    "events = events.join(gb['event_id'].value_counts().unstack().add_prefix('event_id_'), on='ref_hash')\n",
    "events = events.join(gb['application_id'].value_counts().unstack().add_prefix('application_id_'), on='ref_hash')\n",
    "#events = events.join(gb['device_os_version'].value_counts().unstack().add_prefix('device_os_version_'), on='ref_hash')\n",
    "#events = events.join(gb['device_brand'].value_counts().unstack().add_prefix('device_brand_'), on='ref_hash')\n",
    "#events = events.join(gb['device_model'].value_counts().unstack().add_prefix('device_model_'), on='ref_hash')\n",
    "#events = events.join(gb['carrier'].value_counts().unstack().add_prefix('carrier_'), on='ref_hash')\n",
    "events = events.join(gb['session_user_agent'].value_counts().unstack().add_prefix('session_user_agent_'), on='ref_hash')\n",
    "events = events.join(gb['kind'].value_counts().unstack().add_prefix('kind_'), on='ref_hash')\n",
    "#events = events.join(gb['device_language'].value_counts().unstack().add_prefix('device_language_'), on='ref_hash')\n",
    "\n",
    "events['n_events'] = gb['date'].transform('count')\n",
    "events['attributed_events_mean'] = gb['attributed'].transform('mean')\n",
    "events['wifi_events_mean'] = gb['wifi'].transform('mean')\n",
    "events['first_event'] = gb['date'].transform('min')\n",
    "events['last_event'] = gb['date'].transform('max')\n",
    "events['diff_events'] = (events['last_event'] - events['first_event']).dt.total_seconds()\n",
    "events['mean_time_events'] = 0\n",
    "events.loc[events['n_events'] > 1, 'mean_time_events'] = ((events['last_event'] - events['first_event'])/ \\\n",
    "                                 (events['n_events'] -1)).dt.total_seconds()\n",
    "events['first_event_sec'] = (events['first_event'] - pd.Timestamp(time_windows[window-1][0])).dt.total_seconds()\n",
    "events['last_event_sec'] = (events['last_event'] - pd.Timestamp(time_windows[window-1][0])).dt.total_seconds()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "events.drop_duplicates(subset='ref_hash', inplace=True)\n",
    "events = events.drop(columns=['date', 'event_id', 'ref_type', 'application_id', 'attributed', 'device_os_version', 'device_brand', 'device_model', \n",
    "       'device_city', 'session_user_agent', 'user_agent', 'carrier', 'kind', 'device_os', 'wifi', 'connection_type', 'device_language', 'first_event', 'last_event'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "installs = pd.read_pickle('data/installs_w'+str(window)+'.pkl')\n",
    "installs = installs.drop(columns=['device_countrycode', 'ip_address', 'event_uuid', 'click_hash', 'device_brand', 'device_model'])\n",
    "#installs = installs.drop(columns=['device_language', 'device_countrycode', 'ip_address', 'event_uuid', 'device_brand', 'device_model', 'click_hash', 'session_user_agent'])\n",
    "installs.loc[installs['kind'] == 'OPEN', 'kind'] = 'Open'\n",
    "installs.loc[installs['kind'] == 'app open', 'kind'] = 'app_open'\n",
    "installs.loc[installs['kind'] == 'af app open', 'kind'] = 'af_app_opened'\n",
    "installs.loc[installs['kind'] == 'af_app_opend', 'kind'] = 'af_app_opened'\n",
    "installs.loc[installs['kind'] == 'Session Begin', 'kind'] = 'sessionbegin'\n",
    "installs.loc[installs['kind'] == 'signed in', 'kind'] = 'Sign In'\n",
    "top_20_installs_kind = installs['kind'].value_counts().head(20)\n",
    "installs.loc[(~installs['kind'].isin(top_20_installs_kind.index))&(installs['kind'].notnull()), 'kind'] = 'Other'\n",
    "top_15_installs_app = installs['application_id'].value_counts().head(15)\n",
    "installs.loc[(~installs['application_id'].isin(top_15_installs_app.index))&(installs['application_id'].notnull()), 'application_id'] = 'Other'\n",
    "installs['created'] = pd.to_datetime(installs['created'], format='%Y-%m-%d %H:%M:%S')\n",
    "installs['wifi_installs'] = installs['wifi'].map({True: 1, False: 0})\n",
    "installs['attributed'] = installs['attributed'].map({True: 1, False: 0})\n",
    "installs['implicit'] = installs['implicit'].map({True: 1, False: 0})\n",
    "gb = installs.groupby('ref_hash')\n",
    "installs = installs.join(gb['kind'].value_counts().unstack().add_prefix('kind_'), on='ref_hash')\n",
    "installs = installs.join(gb['application_id'].value_counts().unstack().add_prefix('application_id_'), on='ref_hash')\n",
    "installs['wifi_installs_mean'] = gb['wifi_installs'].transform('mean')\n",
    "installs['attributed_installs_mean'] = gb['attributed'].transform('mean')\n",
    "installs['n_installs'] = gb['created'].transform('count')\n",
    "installs['last_install'] = gb['created'].transform('max')\n",
    "installs['first_install'] = gb['created'].transform('min')\n",
    "installs['diff_installs'] = (installs['last_install'] - installs['first_install']).dt.total_seconds()\n",
    "installs['mean_time_install'] = 0\n",
    "installs.loc[installs['n_installs'] > 1, 'mean_time_install'] = ((installs['last_install'] - installs['first_install'])/ \\\n",
    "                                 (installs['n_installs'] -1)).dt.total_seconds()\n",
    "installs['first_install_sec'] = (installs['first_install'] - pd.Timestamp(time_windows[window-1][0])).dt.total_seconds()\n",
    "installs['last_install_sec'] = (installs['last_install'] - pd.Timestamp(time_windows[window-1][0])).dt.total_seconds()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "installs.drop(columns=['created', 'application_id', 'ref_type', 'attributed',\n",
    "       'implicit', 'user_agent', 'kind', 'wifi', 'trans_id', 'device_language',\n",
    "       'wifi_installs', 'last_install', 'first_install', 'session_user_agent'], inplace=True)\n",
    "installs.drop_duplicates(subset='ref_hash', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = pd.read_csv('data/target_competencia_ids.csv')\n",
    "target['ref_hash'] = target['ref_hash'].apply(lambda x: int(str(x)[:-3]))\n",
    "target.drop_duplicates('ref_hash', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = auctions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = pd.merge(model, installs, how='left', on='ref_hash')\n",
    "model = pd.merge(model, events, how='left', on='ref_hash')\n",
    "model = pd.merge(model, clicks, how='left', on='ref_hash')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "if window <= 4:\n",
    "    model = pd.merge(model, auctions_label, on='ref_hash', how='left')\n",
    "    model = pd.merge(model, installs_label, on='ref_hash', how='left')\n",
    "    model['time_appearence'] = model['time_appearence'].fillna(259200)\n",
    "    model['time_appearence_install'] = model['time_appearence_install'].fillna(259200)\n",
    "model.drop_duplicates('ref_hash', inplace=True)\n",
    "uses = 'all'\n",
    "model.to_pickle('data/model/model_' +uses+'_w'+str(window)+'.pkl')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
