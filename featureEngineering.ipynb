{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Armado de features**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "window = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "auctions = pd.read_pickle('data/auctions_w'+str(window)+'.pkl')\n",
    "clicks_w1 = pd.read_pickle('data/clicks_w'+str(window)+'.pkl')\n",
    "installs = pd.read_pickle('data/installs_w'+str(window)+'.pkl')\n",
    "events_w1 = pd.read_pickle('data/events_w'+str(window)+'.pkl')\n",
    "if window <= 4:\n",
    "    auctions_label = pd.read_pickle('data/auctions_w'+str(window)+'_label.pkl')\n",
    "    installs_label = pd.read_pickle('data/installs_w'+str(window)+'_label.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_windows = [('2019-04-18 00:00:00.000000', '2019-04-21 00:00:00.000000'), ('2019-04-19 00:00:00.000000', '2019-04-22 00:00:00.000000'), \n",
    "                ('2019-04-20 00:00:00.000000', '2019-04-23 00:00:00.000000'), ('2019-04-21 00:00:00.000000', '2019-04-24 00:00:00.000000'), \n",
    "                ('2019-04-24 00:00:00.000000', '2019-04-27 00:00:00.000000')]\n",
    "time_labels = [('2019-04-21 00:00:00.000000', '2019-04-24 00:00:00.000000'), ('2019-04-22 00:00:00.000000', '2019-04-25 00:00:00.000000'), \n",
    "               ('2019-04-23 00:00:00.000000', '2019-04-26 00:00:00.000000'), ('2019-04-24 00:00:00.000000', '2019-04-27 00:00:00.000000')]\n",
    "days = [18, 19, 20, 21, 24]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "gb = auctions.groupby('ref_hash')\n",
    "auctions['n_auctions'] = gb['date'].transform('count')\n",
    "auctions['last_auction'] = gb['date'].transform('max')\n",
    "auctions['first_auction'] = gb['date'].transform('min')\n",
    "auctions['diff_auctions'] = (auctions['last_auction'] - auctions['first_auction']).dt.total_seconds()\n",
    "auctions['mean_time_auction'] = 0\n",
    "auctions.loc[auctions['n_auctions'] > 1, 'mean_time_auction'] = ((auctions['last_auction'] - auctions['first_auction'])/ \\\n",
    "                                 (auctions['n_auctions'] -1)).dt.total_seconds()\n",
    "auctions['first_auction_sec'] = (auctions['first_auction'] - pd.Timestamp(time_windows[window-1][0])).dt.total_seconds()\n",
    "auctions['last_auction_sec'] = (auctions['last_auction'] - pd.Timestamp(time_windows[window-1][0])).dt.total_seconds()\n",
    "auctions['ref_type_id_1'] = auctions['ref_type_id'].apply(lambda x: 1 if x==1 else 0)\n",
    "auctions['ref_type_id_7'] = auctions['ref_type_id'].apply(lambda x: 1 if x==7 else 0)\n",
    "auctions = pd.get_dummies(auctions, columns=['source_id'])\n",
    "auctions['day'] = (auctions['date'].dt.day) - days[window-1]\n",
    "gb = auctions.groupby('ref_hash')\n",
    "auctions['mean_day'] = gb['day'].transform('mean')\n",
    "auctions = pd.get_dummies(auctions, columns=['day'])\n",
    "gb = auctions.groupby('ref_hash')\n",
    "auctions['day_0'] = gb['day_0'].transform('sum')\n",
    "auctions['day_1'] = gb['day_1'].transform('sum')\n",
    "auctions['day_2'] = gb['day_2'].transform('sum')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "auctions.drop_duplicates(subset='ref_hash', inplace=True)\n",
    "auctions = auctions[['ref_hash', 'n_auctions', 'diff_auctions', 'mean_time_auction', \n",
    "                     'first_auction_sec', 'last_auction_sec', 'ref_type_id_1',\n",
    "                     'ref_type_id_7', 'source_id_0', 'source_id_1', 'source_id_2',\n",
    "                     'source_id_3', 'source_id_4', 'source_id_5', 'source_id_6',\n",
    "                     'source_id_7', 'source_id_8', 'source_id_9', 'mean_day', \n",
    "                     'day_0', 'day_1', 'day_2']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "gb = clicks_w1.groupby('ref_hash')\n",
    "clicks_w1['n_clicks'] = gb['created'].transform('count')\n",
    "clicks_w1['last_click'] = gb['created'].transform('max')\n",
    "clicks_w1['first_click'] = gb['created'].transform('min')\n",
    "clicks_w1['diff_clicks'] = (clicks_w1['last_click'] - clicks_w1['first_click']).dt.total_seconds()\n",
    "clicks_w1['mean_time_click'] = 0\n",
    "clicks_w1.loc[clicks_w1['n_clicks'] > 1, 'mean_time_click'] = ((clicks_w1['last_click'] - clicks_w1['first_click'])/ \\\n",
    "                                 (clicks_w1['n_clicks'] -1)).dt.total_seconds()\n",
    "clicks_w1['first_click_sec'] = (clicks_w1['first_click'] - pd.Timestamp(time_windows[window-1][0])).dt.total_seconds()\n",
    "clicks_w1['last_click_sec'] = (clicks_w1['last_click'] - pd.Timestamp(time_windows[window-1][0])).dt.total_seconds()\n",
    "clicks_w1['wifi_connection'] = clicks_w1['wifi_connection'].map({True: 1, False: 0})\n",
    "clicks_w1['timeToClick_mean'] = clicks_w1.groupby('ref_hash')['timeToClick'].transform('mean')\n",
    "clicks_w1.loc[clicks_w1.touchX == 'Infinity', 'touchX'] = 1\n",
    "clicks_w1.loc[clicks_w1.touchY == 'Infinity', 'touchY'] = 1\n",
    "clicks_w1[\"touchX\"] = pd.to_numeric(clicks_w1[\"touchX\"])\n",
    "clicks_w1[\"touchY\"] = pd.to_numeric(clicks_w1[\"touchY\"])\n",
    "clicks_w1['touchX_mean'] = clicks_w1.groupby('ref_hash')['touchX'].transform('mean')\n",
    "clicks_w1['touchY_mean'] = clicks_w1.groupby('ref_hash')['touchY'].transform('mean')\n",
    "clicks_w1['latitude_mean'] = clicks_w1.groupby('ref_hash')['latitude'].transform('mean')\n",
    "clicks_w1['longitude_mean'] = clicks_w1.groupby('ref_hash')['longitude'].transform('mean')\n",
    "clicks_w1['timeToClick_mean'] = clicks_w1['timeToClick_mean'].fillna(clicks_w1['timeToClick_mean'].mean())\n",
    "clicks_w1['touchX_mean'] = clicks_w1['touchX_mean'].fillna(clicks_w1['touchX_mean'].mean())\n",
    "clicks_w1['touchY_mean'] = clicks_w1['touchY_mean'].fillna(clicks_w1['touchY_mean'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "clicks_w1.drop_duplicates(subset='ref_hash', inplace=True)\n",
    "clicks_w1 = clicks_w1[['ref_hash', 'touchX_mean', 'touchY_mean', 'timeToClick_mean', 'latitude_mean', 'longitude_mean', \n",
    "                       'n_clicks', 'wifi_connection', 'first_click_sec', 'last_click_sec', 'diff_clicks', 'mean_time_click']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "events_w1.drop(columns=['event_uuid', 'ip_address', 'index', 'device_countrycode'], inplace=True)\n",
    "events_w1['n_events'] = events_w1.groupby('ref_hash')['date'].transform('count')\n",
    "events_w1['attributed'] = events_w1['attributed'].map({True: 1, False: 0})\n",
    "events_w1['wifi'] = events_w1['wifi'].map({True: 1, False: 0})\n",
    "events_w1['attributed_events_mean'] = events_w1.groupby('ref_hash')['attributed'].transform('mean')\n",
    "events_w1['wifi_events_mean'] = events_w1.groupby('ref_hash')['wifi'].transform('mean')\n",
    "events_w1['first_event'] = events_w1.groupby('ref_hash')['date'].transform('min')\n",
    "events_w1['last_event'] = events_w1.groupby('ref_hash')['date'].transform('max')\n",
    "events_w1['diff_events'] = (events_w1['last_event'] - events_w1['first_event']).dt.total_seconds()\n",
    "events_w1['mean_time_events'] = 0\n",
    "events_w1.loc[events_w1['n_events'] > 1, 'mean_time_events'] = ((events_w1['last_event'] - events_w1['first_event'])/ \\\n",
    "                                 (events_w1['n_events'] -1)).dt.total_seconds()\n",
    "events_w1['first_event_sec'] = (events_w1['first_event'] - pd.Timestamp(time_windows[window-1][0])).dt.total_seconds()\n",
    "events_w1['last_event_sec'] = (events_w1['last_event'] - pd.Timestamp(time_windows[window-1][0])).dt.total_seconds()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "events_w1.drop_duplicates(subset='ref_hash', inplace=True)\n",
    "events_w1 = events_w1[['ref_hash', 'first_event_sec', 'last_event_sec', 'n_events', 'attributed_events_mean', 'wifi_events_mean', 'diff_events', 'mean_time_events']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtypes_dict = {'created':'str',  'ref_type': 'category', 'device_brand': np.float32, \\\n",
    "                'device_countrycode': 'category', 'device_language': 'category', \\\n",
    "                 'kind': 'str', 'user_agent': 'str'}\n",
    "\n",
    "installs = pd.read_csv('data/installs.csv.gzip', dtype=dtypes_dict, low_memory=False)\n",
    "installs = installs.drop(columns=['device_language', 'device_countrycode', 'ip_address', 'event_uuid', 'device_brand', \\\n",
    "                         'device_model', 'click_hash', 'session_user_agent'])\n",
    "installs['created'] = pd.to_datetime(installs['created'], format='%Y-%m-%d %H:%M:%S')\n",
    "installs['wifi_installs'] = installs['wifi'].map({True: 1, False: 0})\n",
    "installs['attributed'] = installs['attributed'].map({True: 1, False: 0})\n",
    "installs['implicit'] = installs['implicit'].map({True: 1, False: 0})\n",
    "gb = installs.groupby('ref_hash')\n",
    "installs['wifi_installs_mean'] = gb['wifi_installs'].transform('mean')\n",
    "installs['attributed_installs_mean'] = gb['attributed'].transform('mean')\n",
    "installs['n_installs'] = gb['created'].transform('count')\n",
    "installs['last_install'] = gb['created'].transform('max')\n",
    "installs['first_install'] = gb['created'].transform('min')\n",
    "installs['diff_installs'] = (installs['last_install'] - installs['first_install']).dt.total_seconds()\n",
    "installs['mean_time_install'] = 0\n",
    "installs.loc[installs['n_installs'] > 1, 'mean_time_install'] = ((installs['last_install'] - installs['first_install'])/ \\\n",
    "                                 (installs['n_installs'] -1)).dt.total_seconds()\n",
    "installs['first_install_sec'] = (installs['first_install'] - pd.Timestamp(time_windows[window-1][0])).dt.total_seconds()\n",
    "installs['last_install_sec'] = (installs['last_install'] - pd.Timestamp(time_windows[window-1][0])).dt.total_seconds()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "installs.drop_duplicates(subset='ref_hash', inplace=True)\n",
    "installs = installs[['ref_hash', 'first_install_sec', 'last_install_sec', 'n_installs', 'attributed_installs_mean', 'wifi_installs_mean', 'diff_installs', 'mean_time_install']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = pd.merge(auctions, clicks_w1, on='ref_hash', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = pd.merge(model, installs, on='ref_hash', how='outer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = pd.merge(model, events_w1, on='ref_hash', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(554681, 47)"
      ]
     },
     "execution_count": 217,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "if window <= 4:\n",
    "    model = pd.merge(model, auctions_label, on='ref_hash', how='left')\n",
    "    model = pd.merge(model, installs_label, on='ref_hash', how='left')\n",
    "    model['time_appearence'] = model['time_appearence'].fillna(259200)\n",
    "    model['time_appearence_install'] = model['time_appearence_install'].fillna(259200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.drop_duplicates('ref_hash', inplace=True)\n",
    "model.to_pickle('data/model/model3_w'+str(window)+'.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
